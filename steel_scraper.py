import requests
from bs4 import BeautifulSoup
import logging
import random
from datetime import datetime
import jdatetime
import os
from telegram import Bot
from telegram.error import TelegramError

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('steel_scraper.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

def get_fresh_proxy():
    """Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¬Ø¯ÛŒØ¯ Ùˆ ÙØ¹Ø§Ù„"""
    try:
        # Ù„ÛŒØ³ØªÛŒ Ø§Ø² Ù¾Ø±ÙˆÚ©Ø³ÛŒâ€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒÚ¯Ø§Ù† (Ù…ÛŒâ€ŒØªÙˆØ§Ù†ÛŒØ¯æ‰©å…… Ú©Ù†ÛŒØ¯)
        free_proxies = [
            # 'http://proxy1:port',
            # 'http://proxy2:port',
            # ...
        ]
        
        if free_proxies:
            proxy = random.choice(free_proxies)
            logger.info(f"Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯: {proxy}")
            return {
                'http': proxy,
                'https': proxy
            }
        else:
            logger.info("Ù‡ÛŒÚ† Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³ØªØŒ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯ÙˆÙ† Ù¾Ø±ÙˆÚ©Ø³ÛŒ")
            return None
            
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø±ÙˆÚ©Ø³ÛŒ: {str(e)}")
        return None

def send_telegram_message(message):
    """Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…"""
    try:
        bot_token = os.getenv('BOT_TOKEN')
        chat_id = os.getenv('CHAT_ID')
        
        if not bot_token or not chat_id:
            logger.error("ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª ÛŒØ§ Ú†Øª Ø¢ÛŒØ¯ÛŒ ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
            return False
            
        bot = Bot(token=bot_token)
        bot.send_message(chat_id=chat_id, text=message)
        logger.info("Ù¾ÛŒØ§Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯")
        return True
        
    except TelegramError as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØªÙ„Ú¯Ø±Ø§Ù…: {str(e)}")
        return False
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…: {str(e)}")
        return False

def scrape_milgard_ahanonline():
    """Ø§Ø³Ú©Ø±Ø§Ù¾ Ù‚ÛŒÙ…Øª Ù…ÛŒÙ„Ú¯Ø±Ø¯ Ø§Ø² Ø¢Ù‡Ù† Ø¢Ù†Ù„Ø§ÛŒÙ†"""
    milgard_prices = {}
    max_retries = 3
    
    # ØªØ§Ø±ÛŒØ® Ùˆ Ø³Ø§Ø¹Øª ÙØ¹Ù„ÛŒ
    now = datetime.now()
    jalali_date = jdatetime.datetime.fromgregorian(datetime=now).strftime('%Y/%m/%d %H:%M')
    
    for attempt in range(max_retries):
        try:
            # Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø±ÙˆÚ©Ø³ÛŒ
            proxies = get_fresh_proxy()
            
            url = "https://ahanonline.com/product-category/Ù…ÛŒÙ„Ú¯Ø±Ø¯/Ù‚ÛŒÙ…Øª-Ù…ÛŒÙ„Ú¯Ø±Ø¯/"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'fa-IR,fa;q=0.9,en-US;q=0.8,en;q=0.7',
                'Referer': 'https://ahanonline.com/',
                'Connection': 'keep-alive'
            }
            
            logger.info(f"ØªÙ„Ø§Ø´ {attempt + 1} Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡")
            
            response = requests.get(url, headers=headers, timeout=30, proxies=proxies)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'lxml')
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ (Ø§ÛŒÙ† Ø³Ù„Ú©ØªÙˆØ±Ù‡Ø§ Ù†ÛŒØ§Ø² Ø¨Ù‡ ØªÙ†Ø¸ÛŒÙ… Ø¯Ù‚ÛŒÙ‚ Ø¯Ø§Ø±Ù†Ø¯)
                prices = extract_prices(soup)
                milgard_prices.update(prices)
                
                # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÛŒØ§Ù… Ø¨Ø±Ø§ÛŒ Ø§Ø±Ø³Ø§Ù„
                message = f"ğŸ“Š Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÛŒÙ„Ú¯Ø±Ø¯ - {jalali_date}\n\n"
                
                if milgard_prices:
                    for product, price in milgard_prices.items():
                        message += f"ğŸ”¹ {product}: {price}\n"
                else:
                    message += "âš ï¸ Ù‚ÛŒÙ…ØªÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯\n"
                
                message += f"\nğŸ“ Ù…Ù†Ø¨Ø¹: Ø¢Ù‡Ù† Ø¢Ù†Ù„Ø§ÛŒÙ†"
                
                # Ø§Ø±Ø³Ø§Ù„ Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…
                send_telegram_message(message)
                
                logger.info("Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")
                break
                
            else:
                logger.warning(f"Ø®Ø·Ø§ÛŒ HTTP: {response.status_code}")
                
        except requests.exceptions.RequestException as e:
            logger.warning(f"Ø®Ø·Ø§ÛŒ Ø´Ø¨Ú©Ù‡: {str(e)}ØŒ ØªÙ„Ø§Ø´ Ù…Ø¬Ø¯Ø¯...")
            continue
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³Ú©Ø±Ø§Ù¾: {str(e)}")
            continue
    
    return milgard_prices

def extract_prices(soup):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ Ø§Ø² ØµÙØ­Ù‡"""
    prices = {}
    
    try:
        # Ø§ÛŒÙ† Ø¨Ø®Ø´ Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ù†Ø§Ù„ÛŒØ² Ø¯Ù‚ÛŒÙ‚ Ø³Ø§Ø®ØªØ§Ø± HTML Ø³Ø§ÛŒØª Ø¯Ø§Ø±Ø¯
        # Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙØ±Ø¶ÛŒ:
        
        # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ø§Ù„Ù…Ù†Øªâ€ŒÙ‡Ø§ÛŒ Ø­Ø§ÙˆÛŒ Ù‚ÛŒÙ…Øª
        price_elements = soup.find_all('span', class_='price')
        
        for element in price_elements[:10]:  # Ù…Ø­Ø¯ÙˆØ¯ Ú©Ø±Ø¯Ù† Ø¨Ø±Ø§ÛŒ ØªØ³Øª
            product_name = "Ù…ÛŒÙ„Ú¯Ø±Ø¯ A3"
            price_text = element.get_text(strip=True)
            
            if price_text and 'ØªÙˆÙ…Ø§Ù†' in price_text:
                prices[product_name] = price_text
                
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§: {str(e)}")
    
    # Ø¯Ø§Ø¯Ù‡ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ³Øª
    if not prices:
        prices = {
            'Ù…ÛŒÙ„Ú¯Ø±Ø¯ 16 Ø¢Ø¬Ø¯Ø§Ø±': '325,000 ØªÙˆÙ…Ø§Ù†',
            'Ù…ÛŒÙ„Ú¯Ø±Ø¯ 14 Ø³Ø§Ø¯Ù‡': '310,000 ØªÙˆÙ…Ø§Ù†',
            'Ù…ÛŒÙ„Ú¯Ø±Ø¯ 18 ØµÙ†Ø¹ØªÛŒ': '340,000 ØªÙˆÙ…Ø§Ù†'
        }
    
    return prices

if __name__ == "__main__":
    logger.info("Ø´Ø±ÙˆØ¹ Ø§Ø³Ú©Ø±Ø§Ù¾ Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ ÙÙˆÙ„Ø§Ø¯...")
    prices = scrape_milgard_ahanonline()
    logger.info(f"Ø§Ø³Ú©Ø±Ø§Ù¾ Ğ·Ğ°Ğ²ĞµÑ€ Ø´Ø¯. {len(prices)} Ù‚ÛŒÙ…Øª ÛŒØ§ÙØª Ø´Ø¯.")
