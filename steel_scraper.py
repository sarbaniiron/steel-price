import requests
from bs4 import BeautifulSoup
import logging
import random
from datetime import datetime
import jdatetime
import os
from telegram import Bot
from telegram.error import TelegramError

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('steel_scraper.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("steel_scraper")

def get_fresh_proxy():
    """Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¬Ø¯ÛŒØ¯ Ùˆ ÙØ¹Ø§Ù„ (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)"""
    try:
        free_proxies = [
            # 'http://proxy1:port',
            # 'http://proxy2:port',
        ]
        
        if free_proxies:
            proxy = random.choice(free_proxies)
            logger.info(f"Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯: {proxy}")
            return {'http': proxy, 'https': proxy}
        else:
            logger.info("Ù‡ÛŒÚ† Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³ØªØŒ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯ÙˆÙ† Ù¾Ø±ÙˆÚ©Ø³ÛŒ")
            return None
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø±ÙˆÚ©Ø³ÛŒ: {str(e)}")
        return None

def send_telegram_message(message):
    """Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…"""
    try:
        bot_token = os.getenv('BOT_TOKEN')
        chat_id = os.getenv('CHAT_ID')
        
        if not bot_token or not chat_id:
            logger.error("ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª ÛŒØ§ Ú†Øª Ø¢ÛŒØ¯ÛŒ ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
            return False
        
        bot = Bot(token=bot_token)
        bot.send_message(chat_id=chat_id, text=message, parse_mode="HTML")
        logger.info("Ù¾ÛŒØ§Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯")
        return True
        
    except TelegramError as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØªÙ„Ú¯Ø±Ø§Ù…: {str(e)}")
        return False
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…: {str(e)}")
        return False

def extract_prices(soup):
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª Ù…ÛŒÙ„Ú¯Ø±Ø¯ Ø§Ø² ØµÙØ­Ù‡ Ø¢Ù‡Ù†â€ŒØ¢Ù†Ù„Ø§ÛŒÙ†
    Ø®Ø±ÙˆØ¬ÛŒ: Ø¯ÛŒÚ©Ø´Ù†Ø±ÛŒ {(factory, size): price}
    """
    prices = {}

    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù‡Ø± Ø¨Ø®Ø´ Ø¨Ø±Ù†Ø¯ (Ú©Ø§Ø±Ø®Ø§Ù†Ù‡)
    brand_sections = soup.select("div.products > ul > li")

    for brand in brand_sections:
        factory_tag = brand.select_one("h2 a")
        if not factory_tag:
            continue
        factory_name = factory_tag.get_text(strip=True)

        # Ø±Ø¯ÛŒÙâ€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÙˆÙ„ Ù‚ÛŒÙ…Øª
        rows = brand.select("table tr")[1:]  # Ø­Ø°Ù Ù‡Ø¯Ø± Ø¬Ø¯ÙˆÙ„
        for row in rows:
            cols = row.find_all("td")
            if len(cols) >= 3:
                size = cols[0].get_text(strip=True)
                price = cols[2].get_text(strip=True)
                prices[(factory_name, size)] = price

    return prices

def scrape_milgard_ahanonline():
    """Ø§Ø³Ú©Ø±Ø§Ù¾ Ù‚ÛŒÙ…Øª Ù…ÛŒÙ„Ú¯Ø±Ø¯ Ø§Ø² Ø¢Ù‡Ù† Ø¢Ù†Ù„Ø§ÛŒÙ†"""
    milgard_prices = {}
    max_retries = 3
    
    # ØªØ§Ø±ÛŒØ® Ùˆ Ø³Ø§Ø¹Øª ÙØ¹Ù„ÛŒ
    now = datetime.now()
    jalali_date = jdatetime.datetime.fromgregorian(datetime=now).strftime('%Y/%m/%d %H:%M')
    
    for attempt in range(max_retries):
        try:
            proxies = get_fresh_proxy()
            url = "https://ahanonline.com/product-category/%D9%85%DB%8C%D9%84%DA%AF%D8%B1%D8%AF/%D9%82%DB%8C%D9%85%D8%AA-%D9%85%DB%8C%D9%84%DA%AF%D8%B1%D8%AF/"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'fa-IR,fa;q=0.9,en-US;q=0.8,en;q=0.7',
                'Referer': 'https://ahanonline.com/',
                'Connection': 'keep-alive'
            }
            
            logger.info(f"ØªÙ„Ø§Ø´ {attempt + 1} Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡")
            response = requests.get(url, headers=headers, timeout=30, proxies=proxies)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'lxml')
                prices = extract_prices(soup)
                milgard_prices.update(prices)
                
                # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù…
                message = f"ğŸ“Š Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÛŒÙ„Ú¯Ø±Ø¯ - {jalali_date}\n\n"
                if milgard_prices:
                    grouped = {}
                    for (factory, size), price in milgard_prices.items():
                        grouped.setdefault(factory, []).append((size, price))

                    for factory, items in grouped.items():
                        message += f"ğŸ­ <b>{factory}</b>\n"
                        for size, price in sorted(items, key=lambda x: int(x[0]) if x[0].isdigit() else 999):
                            message += f"   ğŸ”¹ Ø³Ø§ÛŒØ² {size}: {price}\n"
                        message += "\n"
                else:
                    message += "âš ï¸ Ù‚ÛŒÙ…ØªÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯\n"
                
                message += "ğŸ“ Ù…Ù†Ø¨Ø¹: Ø¢Ù‡Ù† Ø¢Ù†Ù„Ø§ÛŒÙ†"
                
                send_telegram_message(message)
                logger.info("Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ù…ÙˆÙÙ‚ÛŒØªâ€ŒØ¢Ù…ÛŒØ² Ø¨ÙˆØ¯")
                break
            else:
                logger.warning(f"HTTP response status: {response.status_code}")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªÙ„Ø§Ø´ {attempt + 1}: {e}")

if __name__ == "__main__":
    scrape_milgard_ahanonline()
