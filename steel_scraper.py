import requests
from bs4 import BeautifulSoup
import logging
import random
from datetime import datetime
import jdatetime
import os
from telegram import Bot
from telegram.error import TelegramError

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù„Ø§Ú¯â€ŒÚ¯ÛŒØ±ÛŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('steel_scraper.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger("steel_scraper")


def get_fresh_proxy():
    """Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¬Ø¯ÛŒØ¯ Ùˆ ÙØ¹Ø§Ù„"""
    try:
        free_proxies = [
            # 'http://proxy1:port',
            # 'http://proxy2:port',
        ]
        
        if free_proxies:
            proxy = random.choice(free_proxies)
            logger.info(f"Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø§Ù†ØªØ®Ø§Ø¨ Ø´Ø¯: {proxy}")
            return {'http': proxy, 'https': proxy}
        else:
            logger.info("Ù‡ÛŒÚ† Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ Ù†ÛŒØ³ØªØŒ Ø§Ø¯Ø§Ù…Ù‡ Ø¨Ø¯ÙˆÙ† Ù¾Ø±ÙˆÚ©Ø³ÛŒ")
            return None
            
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ù¾Ø±ÙˆÚ©Ø³ÛŒ: {str(e)}")
        return None


def send_telegram_message(message):
    """Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… Ø¨Ù‡ ØªÙ„Ú¯Ø±Ø§Ù…"""
    try:
        bot_token = os.getenv('BOT_TOKEN')
        chat_id = os.getenv('CHAT_ID')
        
        if not bot_token or not chat_id:
            logger.error("ØªÙˆÚ©Ù† Ø±Ø¨Ø§Øª ÛŒØ§ Ú†Øª Ø¢ÛŒØ¯ÛŒ ØªÙ†Ø¸ÛŒÙ… Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
            return False
            
        bot = Bot(token=bot_token)
        bot.send_message(chat_id=chat_id, text=message, parse_mode="HTML")
        logger.info("Ù¾ÛŒØ§Ù… Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯")
        return True
        
    except TelegramError as e:
        logger.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù… ØªÙ„Ú¯Ø±Ø§Ù…: {str(e)}")
        return False
    except Exception as e:
        logger.error(f"Ø®Ø·Ø§ÛŒ ØºÛŒØ±Ù…Ù†ØªØ¸Ø±Ù‡ Ø¯Ø± Ø§Ø±Ø³Ø§Ù„ Ù¾ÛŒØ§Ù…: {str(e)}")
        return False


def extract_prices(soup):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÛŒÙ…Øª Ù…ÛŒÙ„Ú¯Ø±Ø¯ Ø§Ø² ØµÙØ­Ù‡ Ùˆ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø¨Ø± Ø§Ø³Ø§Ø³ Ú©Ø§Ø±Ø®Ø§Ù†Ù‡ Ùˆ Ø³Ø§ÛŒØ²"""
    prices = {}

    # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…Ø­ØµÙˆÙ„Ø§Øª
    products = soup.select("div.product-item, li.product")  # Ø¨Ø³ØªÚ¯ÛŒ Ø¨Ù‡ Ø³Ø§Ø®ØªØ§Ø± Ø³Ø§ÛŒØª Ø¯Ø§Ø±Ù‡

    for product in products:
        # Ø¹Ù†ÙˆØ§Ù† Ù…Ø­ØµÙˆÙ„
        title = product.select_one("h2.woocommerce-loop-product__title")
        if not title:
            continue
        title_text = title.get_text(strip=True)

        # Ù‚ÛŒÙ…Øª Ù…Ø­ØµÙˆÙ„
        price_tag = product.select_one("span.woocommerce-Price-amount")
        if not price_tag:
            continue
        price_text = price_tag.get_text(strip=True)

        # ØªØ¹ÛŒÛŒÙ† Ú©Ø§Ø±Ø®Ø§Ù†Ù‡
        factory = "Ù†Ø§Ù…Ø´Ø®Øµ"
        if "Ø°ÙˆØ¨" in title_text:
            factory = "Ø°ÙˆØ¨â€ŒØ¢Ù‡Ù† Ø§ØµÙÙ‡Ø§Ù†"
        elif "Ù…ÛŒØ§Ù†Ù‡" in title_text:
            factory = "Ù…ÛŒØ§Ù†Ù‡"
        elif "ÙØ§ÛŒÚ©Ùˆ" in title_text:
            factory = "ÙØ§ÛŒÚ©Ùˆ"
        elif "Ø¨Ù†Ø§Ø¨" in title_text:
            factory = "Ø¨Ù†Ø§Ø¨"

        # ØªØ¹ÛŒÛŒÙ† Ø³Ø§ÛŒØ²
        size = "Ù†Ø§Ù…Ø´Ø®Øµ"
        for s in range(8, 40):  # Ø³Ø§ÛŒØ²Ù‡Ø§ÛŒ Ù…Ø¹Ù…ÙˆÙ„ Ù…ÛŒÙ„Ú¯Ø±Ø¯
            if f"{s}" in title_text:
                size = f"{s}"
                break

        key = (factory, size)
        prices[key] = price_text

    return prices


def scrape_milgard_ahanonline():
    """Ø§Ø³Ú©Ø±Ø§Ù¾ Ù‚ÛŒÙ…Øª Ù…ÛŒÙ„Ú¯Ø±Ø¯ Ø§Ø² Ø¢Ù‡Ù† Ø¢Ù†Ù„Ø§ÛŒÙ†"""
    milgard_prices = {}
    max_retries = 3
    
    # ØªØ§Ø±ÛŒØ® Ùˆ Ø³Ø§Ø¹Øª ÙØ¹Ù„ÛŒ
    now = datetime.now()
    jalali_date = jdatetime.datetime.fromgregorian(datetime=now).strftime('%Y/%m/%d %H:%M')
    
    for attempt in range(max_retries):
        try:
            proxies = get_fresh_proxy()
            url = "https://ahanonline.com/product-category/Ù…ÛŒÙ„Ú¯Ø±Ø¯/Ù‚ÛŒÙ…Øª-Ù…ÛŒÙ„Ú¯Ø±Ø¯/"
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
                'Accept-Language': 'fa-IR,fa;q=0.9,en-US;q=0.8,en;q=0.7',
                'Referer': 'https://ahanonline.com/',
                'Connection': 'keep-alive'
            }
            
            logger.info(f"ØªÙ„Ø§Ø´ {attempt + 1} Ø¨Ø±Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡")
            response = requests.get(url, headers=headers, timeout=30, proxies=proxies)
            
            if response.status_code == 200:
                soup = BeautifulSoup(response.content, 'lxml')
                prices = extract_prices(soup)
                milgard_prices.update(prices)
                
                # Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù…
                message = f"ğŸ“Š Ù‚ÛŒÙ…Øªâ€ŒÙ‡Ø§ÛŒ Ù…ÛŒÙ„Ú¯Ø±Ø¯ - {jalali_date}\n\n"
                if milgard_prices:
                    grouped = {}
                    for (factory, size), price in milgard_prices.items():
                        grouped.setdefault(factory, []).append((size, price))

                    for factory, items in grouped.items():
                        message += f"ğŸ­ <b>{factory}</b>\n"
                        for size, price in sorted(items, key=lambda x: int(x[0]) if x[0].isdigit() else 999):
                            message += f"   ğŸ”¹ Ø³Ø§ÛŒØ² {size}: {price}\n"
                        message += "\n"
                else:
                    message += "âš ï¸ Ù‚ÛŒÙ…ØªÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯\n"
                
                message += "ğŸ“ Ù…Ù†Ø¨Ø¹: Ø¢Ù‡Ù† Ø¢Ù†Ù„Ø§ÛŒÙ†"
                
                # Ø§Ø±Ø³Ø§Ù„
                send_telegram_message(message)
                logger.info("Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ùˆ Ø§Ø±Ø³Ø§Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")
                break
            else:
                logger.warning(f"Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¯Ø§Ø¯Ù‡ØŒ Ú©Ø¯ ÙˆØ¶Ø¹ÛŒØª: {response.status_code}")
        except Exception as e:
            logger.error(f"Ø®Ø·Ø§ Ø¯Ø± ØªÙ„Ø§Ø´ {attempt + 1}: {str(e)}")


if __name__ == "__main__":
    scrape_milgard_ahanonline()
